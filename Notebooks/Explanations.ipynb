{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dzhJMuk6MGv2"
      },
      "outputs": [],
      "source": [
        "# Now lets download the trained model from the last notebook using joblib\n",
        "import joblib\n",
        "\n",
        "# Load the trained model from last notebook\n",
        "model = joblib.load('/content/drive/MyDrive/Colab Notebooks/XAIentists/Trained Models/xgboost_model.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "dZaZxSIEMGv3"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "import lime\n",
        "import lime.lime_tabular\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xgboost\n",
        "import xgboost\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import OneHotEncoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "aArS9oWsMGv4"
      },
      "outputs": [],
      "source": [
        "data =pd.read_csv('/content/drive/MyDrive/Colab Notebooks/XAIentists/Data/Processed/compas-scores-two-years-processed.csv')\n",
        "\n",
        "# Drop the two target columns\n",
        "X = data.drop('two_year_recid', axis=1)\n",
        "y = data['two_year_recid']\n",
        "\n",
        "#model = joblib.load('../Trained Models/xgboost_model.pkl')\n",
        "\n",
        "model = joblib.load(\"/content/drive/MyDrive/Colab Notebooks/XAIentists/Trained Models/xgboost_model.pkl\", mmap_mode=\"r\")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "#rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "#rf_model.fit(X_train, y_train)\n",
        "\n",
        "feature_names = X_train.columns.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test.shape)  # Ensure it has 19 features as in the training set\n",
        "print(X_train.shape) # Ensure it has 19 features as well\n",
        "print(instance.shape) # This should return (19,) for 19 features"
      ],
      "metadata": {
        "id": "Z5WXqovHVyEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "X_train_encoded = encoder.fit_transform(X_train)\n",
        "\n",
        "# Ensure it's a NumPy array\n",
        "X_train_encoded = pd.DataFrame(X_train_encoded)"
      ],
      "metadata": {
        "id": "Jr0p1vdlUtih"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Vjppzo0MGv4"
      },
      "outputs": [],
      "source": [
        "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
        "    X_train_encoded.values,\n",
        "    training_labels=y_train,\n",
        "    feature_names=encoder.get_feature_names_out(),\n",
        "    class_names=[\"No Recidivism\", \"Recidivism\"],\n",
        "    mode=\"classification\"\n",
        ")\n",
        "# Select a sample instance from the test set\n",
        "i = 5  # Choose any index\n",
        "instance = X_test.iloc[i].values\n",
        "X_test = X_test[X_train.columns]  # Ensure X_test has the same columns as X_train\n",
        "\n",
        "#instance = X_train.iloc[0]  # Ensure it's a valid row from your training data\n",
        "\n",
        "# Generate explanation\n",
        "exp = explainer.explain_instance(instance, model.predict_proba, num_features=10)\n",
        "\n",
        "# Visualize explanation\n",
        "exp.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)  # Check the shape of the dataset\n",
        "\n",
        "dmatrix = xgb.DMatrix(X_train, enable_categorical=True)\n",
        "print(dmatrix.num_row())  # Verify the number of rows in the DMatrix\n",
        "print(dmatrix.num_col())"
      ],
      "metadata": {
        "id": "PfBp5qapbyDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wANt07s_cAd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For numeric columns, you can fill missing values with the mean or median\n",
        "#X_train['r_days_from_arrest'].fillna(X_train['r_days_from_arrest'].mean(), inplace=True)\n",
        "X_train['r_days_from_arrest'] = X_train['r_days_from_arrest'].fillna(X_train['r_days_from_arrest'].mean())\n",
        "#X_train['r_charge_desc'].fillna(X_train['r_charge_desc'].mean(), inplace=True)\n",
        "X_train['r_charge_desc'] = X_train['r_charge_desc'].fillna(X_train['r_charge_desc'].mean())\n",
        "#X_train['vr_charge_desc'].fillna(X_train['vr_charge_desc'].mean(), inplace=True)\n",
        "X_train['vr_charge_desc'] = X_train['vr_charge_desc'].fillna(X_train['vr_charge_desc'].mean())\n",
        "#X_train['r_length_of_stay'].fillna(X_train['r_length_of_stay'].mean(), inplace=True)\n",
        "X_train['r_length_of_stay'] = X_train['r_length_of_stay'].fillna(X_train['r_length_of_stay'].mean())"
      ],
      "metadata": {
        "id": "zJV1NFN3dCl_"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows with any missing values\n",
        "X_train.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "Ypmb2P1KdQrN"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.isna().sum())  # Check for missing values in the dataset\n",
        "\n",
        "print(X_train.shape)  # Check if the number of rows and columns have changed"
      ],
      "metadata": {
        "id": "AyEJA_uvdGgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zqarhux4MGv5"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import xgboost as xgb\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "X_train['sex'] = label_encoder.fit_transform(X_train['sex'])\n",
        "X_train['age_cat'] = label_encoder.fit_transform(X_train['age_cat'])\n",
        "X_train['race'] = label_encoder.fit_transform(X_train['race'])\n",
        "X_train['c_charge_degree'] = label_encoder.fit_transform(X_train['c_charge_degree'])\n",
        "X_train['r_charge_degree'] = label_encoder.fit_transform(X_train['r_charge_degree'])\n",
        "X_train['vr_charge_degree'] = label_encoder.fit_transform(X_train['vr_charge_degree'])\n",
        "\n",
        "dmatrix = xgb.DMatrix(X_train, enable_categorical=True)\n",
        "\n",
        "# Create SHAP explainer\n",
        "explainer = shap.TreeExplainer(model)  # Random Forest is tree-based\n",
        "\n",
        "X_train['sex'] = X_train['sex'].astype('category')\n",
        "\n",
        "# Compute SHAP values\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "#shap_values = explainer.shap_values(dmatrix)\n",
        "\n",
        "# Summary plot (global feature importance)\n",
        "shap.summary_plot(shap_values[1], X_test, feature_names=feature_names)  # Class 1 (Recidivism)\n",
        "\n",
        "# Explanation for a single instance\n",
        "shap.force_plot(explainer.expected_value[1], shap_values[1][i], X_test.iloc[i], matplotlib=True)\n",
        "\n",
        "# Initialize JavaScript visualization to understand how the model makes decisions (for each feature)\n",
        "shap.initjs()\n",
        "shap.force_plot(shap_values[1][0], X_test[0], feature_names=feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2_MKPy5MGv5"
      },
      "outputs": [],
      "source": [
        "# Check the data types of all columns\n",
        "print(X_train.dtypes)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}