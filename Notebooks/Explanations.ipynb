{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dzhJMuk6MGv2"
      },
      "outputs": [],
      "source": [
        "# Now lets download the trained model from the last notebook using joblib\n",
        "import joblib\n",
        "\n",
        "# Load the trained model from last notebook\n",
        "model = joblib.load('/content/drive/MyDrive/Colab Notebooks/XAIentists/Trained Models/xgboost_model.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "dZaZxSIEMGv3"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "import lime\n",
        "import lime.lime_tabular\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xgboost\n",
        "import xgboost\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import OneHotEncoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Vjppzo0MGv4"
      },
      "outputs": [],
      "source": [
        "data =pd.read_csv('/content/drive/MyDrive/Colab Notebooks/XAIentists/Data/Processed/compas-scores-two-years-processed.csv')\n",
        "\n",
        "# Drop the two target columns\n",
        "X = data.drop('two_year_recid', axis=1)\n",
        "y = data['two_year_recid']\n",
        "\n",
        "#model = joblib.load('../Trained Models/xgboost_model.pkl')\n",
        "\n",
        "model = joblib.load(\"/content/drive/MyDrive/Colab Notebooks/XAIentists/Trained Models/xgboost_model.pkl\", mmap_mode=\"r\")\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import pandas as pd\n",
        "\n",
        "# Identify categorical columns\n",
        "categorical_cols = X.select_dtypes(include=[\"object\"]).columns\n",
        "\n",
        "# Initialize OneHotEncoder\n",
        "encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False, max_categories=10)\n",
        "\n",
        "# Fit only on training data\n",
        "X_train_encoded = encoder.fit_transform(X_train)\n",
        "\n",
        "# Apply the same transformation to test data (no .fit, only .transform!)\n",
        "X_test_encoded = encoder.transform(X_test)\n",
        "\n",
        "# Convert to DataFrame\n",
        "X_train_encoded = pd.DataFrame(X_train_encoded, columns=encoder.get_feature_names_out())\n",
        "X_test_encoded = pd.DataFrame(X_test_encoded, columns=encoder.get_feature_names_out())\n",
        "\n",
        "# Ensure X_test has the same columns as X_train\n",
        "X_test_encoded = X_test_encoded.reindex(columns=X_train_encoded.columns, fill_value=0)\n",
        "\n",
        "print(\"X_train_encoded shape:\", X_train_encoded.shape)  # Should match the model's expectation\n",
        "print(\"X_test_encoded shape:\", X_test_encoded.shape)    # Should be the same as X_train\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
        "# Train the model on the correctly encoded data\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train_encoded, y_train)\n",
        "\n",
        "# Now the model can correctly predict using X_test_encoded\n",
        "#predictions = model.predict(X_test_encoded)\n",
        "\n",
        "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
        "    X_test_encoded.values,\n",
        "    feature_names=X_train_encoded.columns.tolist(),\n",
        "    class_names=[\"No Recidivism\", \"Recidivism\"],\n",
        "    mode=\"classification\"\n",
        ")\n",
        "\n",
        "# Select a sample instance from the test set\n",
        "i = 5  # Choose any index\n",
        "instance = X_test_encoded.iloc[[i]]\n",
        "X_test = X_test[X_train.columns]  # Ensure X_test has the same columns as X_train\n",
        "\n",
        "# Convert instance to a DataFrame with the correct column names\n",
        "instance_for_lime = pd.DataFrame([instance.iloc[0].values], columns=X_train_encoded.columns)\n",
        "\n",
        "# Now pass this to LIME\n",
        "exp = explainer.explain_instance(instance_for_lime.iloc[0].values, model.predict_proba, num_features=10)\n",
        "\n",
        "\n",
        "# Print prediction\n",
        "prediction = model.predict(instance)\n",
        "print(\"instance:\", instance)\n",
        "print(\"prediction:\", prediction)\n",
        "\n",
        "# Generate explanation\n",
        "#exp = explainer.explain_instance(instance.iloc[0].values, model.predict_proba, num_features=10)\n",
        "\n",
        "# Print the explanation\n",
        "print(exp.as_list())\n",
        "\n",
        "# Visualize explanation\n",
        "exp.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.predict_proba(instance))"
      ],
      "metadata": {
        "id": "ko0vbgL3228w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)  # Check the shape of the dataset"
      ],
      "metadata": {
        "id": "PfBp5qapbyDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For numeric columns, you can fill missing values with the mean or median\n",
        "#X_train['r_days_from_arrest'].fillna(X_train['r_days_from_arrest'].mean(), inplace=True)\n",
        "X_train['r_days_from_arrest'] = X_train['r_days_from_arrest'].fillna(X_train['r_days_from_arrest'].mean())\n",
        "#X_train['r_charge_desc'].fillna(X_train['r_charge_desc'].mean(), inplace=True)\n",
        "X_train['r_charge_desc'] = X_train['r_charge_desc'].fillna(X_train['r_charge_desc'].mean())\n",
        "#X_train['vr_charge_desc'].fillna(X_train['vr_charge_desc'].mean(), inplace=True)\n",
        "X_train['vr_charge_desc'] = X_train['vr_charge_desc'].fillna(X_train['vr_charge_desc'].mean())\n",
        "#X_train['r_length_of_stay'].fillna(X_train['r_length_of_stay'].mean(), inplace=True)\n",
        "X_train['r_length_of_stay'] = X_train['r_length_of_stay'].fillna(X_train['r_length_of_stay'].mean())"
      ],
      "metadata": {
        "id": "zJV1NFN3dCl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows with any missing values\n",
        "X_train.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "Ypmb2P1KdQrN"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.isna().sum())  # Check for missing values in the dataset\n",
        "\n",
        "print(X_train.shape)  # Check if the number of rows and columns have changed"
      ],
      "metadata": {
        "id": "AyEJA_uvdGgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zqarhux4MGv5"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import xgboost as xgb\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "X_train['sex'] = label_encoder.fit_transform(X_train['sex'])\n",
        "X_train['age_cat'] = label_encoder.fit_transform(X_train['age_cat'])\n",
        "X_train['race'] = label_encoder.fit_transform(X_train['race'])\n",
        "X_train['c_charge_degree'] = label_encoder.fit_transform(X_train['c_charge_degree'])\n",
        "X_train['r_charge_degree'] = label_encoder.fit_transform(X_train['r_charge_degree'])\n",
        "X_train['vr_charge_degree'] = label_encoder.fit_transform(X_train['vr_charge_degree'])\n",
        "\n",
        "dmatrix = xgb.DMatrix(X_train, enable_categorical=True)\n",
        "\n",
        "# Create SHAP explainer\n",
        "explainer = shap.TreeExplainer(model)  # Random Forest is tree-based\n",
        "\n",
        "X_train['sex'] = X_train['sex'].astype('category')\n",
        "\n",
        "# Compute SHAP values\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "#shap_values = explainer.shap_values(dmatrix)\n",
        "\n",
        "# Summary plot (global feature importance)\n",
        "shap.summary_plot(shap_values[1], X_test, feature_names=feature_names)  # Class 1 (Recidivism)\n",
        "\n",
        "# Explanation for a single instance\n",
        "shap.force_plot(explainer.expected_value[1], shap_values[1][i], X_test.iloc[i], matplotlib=True)\n",
        "\n",
        "# Initialize JavaScript visualization to understand how the model makes decisions (for each feature)\n",
        "shap.initjs()\n",
        "shap.force_plot(shap_values[1][0], X_test[0], feature_names=feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2_MKPy5MGv5"
      },
      "outputs": [],
      "source": [
        "# Check the data types of all columns\n",
        "print(X_train.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Load the trained model\n",
        "model = joblib.load(\"/content/drive/MyDrive/Colab Notebooks/XAIentists/Trained Models/xgboost_model.pkl\")\n",
        "\n",
        "# Get feature names\n",
        "expected_features = model.feature_names_in_\n",
        "print(\"Model was trained with these features:\", expected_features)\n",
        "print(\"Number of features used in training:\", len(expected_features))\n",
        "print(\"Model expects:\", model.n_features_in_, \"features\")  # Expected feature count\n",
        "\n",
        "# Ensure X_test_encoded has the same columns as in the trained model\n",
        "X_test_encoded = X_test_encoded.reindex(columns=expected_features, fill_value=0)\n",
        "\n",
        "print(\"Final shape of X_test_encoded:\", X_test_encoded.shape)  # Should be (n_samples, 45)"
      ],
      "metadata": {
        "id": "AFXp40KfsVUx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}